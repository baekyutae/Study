# 기본 개념

Priority Queue

일반 큐의 경우 먼저 온 사람이 먼저 나가는 형태(FIFO)이지만 우선순위큐는 우선순위가 높은 사람 먼저 나가는형태의 자료형이다. (들어온 순서는 무관함)

우선순위큐를 구현하는 방법은 List와 Heap이 있으며 주로 Heap 사용한다

리스트의 경우 꺼낼때 마다 전체를 뒤지거나 정렬(sort)후 꺼내야해 시간복잡도가 O(N) or O(NlogN) 이지만 Heap은 O(logN)이라 압도적으로 효율이 좋음

때문에 우선순위큐를 쓴다하면 heap을 사용하는 것과 거의 같은 의미

# Priority Queue 구현 라이브러리

## 1) heapq

파이썬은 우선순위 큐를 위해 `heapq`라는 내장 모듈을 제공
`heapq`는 기본적으로 최소 힙(Min Heap)이다
즉, 숫자가 작은 것이 우선순위가 높음

```python

import heapq

q = []

# 1. 데이터 넣기 (Push)
heapq.heappush(q, 10)
heapq.heappush(q, 1)  # 1이 제일 작으므로 앞으로 옴
heapq.heappush(q, 5)

# 2. 데이터 꺼내기 (Pop) - 가장 작은 값부터 나옴
print(heapq.heappop(q)) # 1 출력
print(heapq.heappop(q)) # 5 출력
print(heapq.heappop(q)) # 10 출력
```

예시와 같이 순서 상관없이 우선순위 큐에 넣어도 가장 작은 값부터 출력됨을 확인 할수 있다.

```python
import heapq

q = []
nums = [1, 10, 5]

# 넣을 때: 부호를 마이너스로 바꿔서 넣음 (-1, -10, -5)
# 이러면 -10이 가장 작은 수가 되어 힙의 맨 앞에 위치함
for n in nums:
    heapq.heappush(q, -n) 

# 꺼낼 때: 다시 마이너스를 붙여서 원상복구
print(-heapq.heappop(q)) # -(-10) = 10 출력
```

마이너스로 부호를 바꾸는 방식으로 큰수부터 나오게 할수 있고 별도의 옵션은 존재하지 않는다.

## 2) queue.PriorityQueue

파이썬의 표준 라이브러리인 `queue` 모듈에 포함된 클래스(설치 불필요)로, '멀티 스레딩(Multi-threading) 환경'을 위해 설계된 우선순위 큐

우선순위를 정렬하는 핵심 알고리즘을 직접 새로 짜지 않고, 이미 존재하는 `heapq` 모듈의 함수를 가져와서 호출(Call) 하는 방식이다

### **heapq와의 차이점은 동기화(Synchronization)**

**동기화** : 동시성으로 인해 여러 작업이 마구 돌아갈 때, **순서나 자원 접근을 제어**하는 기술 

`heapq`는 오직 "리스트 내부의 데이터를 힙(Heap) 규칙에 맞게 재배열(Sort/Swap)"하는 수학적/논리적 기능만 수행 때문에, 여러 스레드가 동시에 접근하면 데이터가 꼬일 수 있다. 

=> 레이스 컨디션 문제

`heappop()` 같은 함수는 컴퓨터 내부에서 **읽기 → 수정 → 쓰기**의 3단계를 거치는데, 이 과정이 원자적(Atomic)이지 않음.

**시나리오: 스레드 A와 B가 동시에 `pop` 시도**

1. **A가 확인:** "마지막 값(10) 있네." (아직 삭제 안 함)
     
2. **--- 문맥 교환 (A 멈춤, B 시작) ---**
    
3. **B가 확인:** "마지막 값(10) 있네."
   
4. **B가 삭제:** 10을 삭제하고 저장함.

5. . **--- 문맥 교환 (B 멈춤, A 재개) ---**
    
6. **A가 삭제 시도:** "아까 본 10 지워야지" → **이미 없으므로 `IndexError` 발생! **

반면 `queue.PriorityQueue`는 다음과 같은 안전장치를 가지고 있음

- **Mutex (Lock):** 한 번에 하나의 스레드만 큐에 접근할 수 있게 한다. (누가 `put`을 하고 있으면 다른 스레드는 `get`을 못 하고 기다려야 함)
    
- **Condition Variable (상태 대기):** 큐가 비어있을 때 `get()`을 호출하면, 데이터가 들어올 때까지 **프로그램(스레드)을 잠시 멈추고(Block) 기다리게** 한다.

대신 아래와 같은 사유로  PiriorityQueue 가 heapq 보다 느리다.

1. Lock 기능 유무: 데이터를 넣고 뺄 때마다 운영체제에게 Lock을 요청하고 해제하는 **오버헤드(추가 비용)가 발생

2. 구현 방식 차이: `heapq`는 **C언어**로 작성된 코드가 바로 실행 `PriorityQueue`는 파이썬 클래스가 `heapq`를 감싸고 있는 **래퍼(Wrapper)** 형태.때문에 함수 호출과 부가적인 로직(If문 체크 등)을 거쳐야 하므로 느리다.

	put()함수 호출 -> lock 요청 -> 큐 꽉찼는지 확인(if문) -> heapq함수 호출(리스트 맨뒤에 값 추가, 부모 노드와 비교) -> 대기중인 다른 스레드에게 데이터 저장을 알림 -> lock 해제

### **주요 메서드와 특징**

- **`put(item)`**: 데이터 넣기. (내부적으로 `heappush` 수행)
    
    - 기본적으로 큐가 꽉 차지 않았다면 바로 넣는다. (`maxsize` 설정 가능)
        
- **`get()`**: 데이터를 꺼낸다. (내부적으로 `heappop` 수행)
    
    - **중요:** 만약 큐가 비어있다면, 데이터가 들어올 때까지 **무한정 기다린다(Blocking).**
        
    - `get(block=False)`로 설정하면 기다리지 않고 바로 에러(`Empty`)를 발생
        
- **`qsize()`**: 현재 큐의 크기를 반환.
    
- **`task_done()` & `join()`**: 작업 관리를 위해 사용. (아래 예제에서 설명)

### 코드 예시(스레드 환경)

```python
import threading
import queue
import time
import random

# 우선순위 큐 생성
pq = queue.PriorityQueue()

def producer():
    """데이터를 만들어 큐에 넣는 역할"""
    for i in range(5):
        priority = random.randint(1, 10)
        item = f"작업-{i}"
        print(f"[생산] {item} (우선순위: {priority}) 넣음")
        
        # (우선순위, 데이터) 튜플 형태로 저장
        pq.put((priority, item)) 
        time.sleep(0.5)

def consumer():
    """큐에서 데이터를 꺼내 처리하는 역할"""
    while True:
        # 큐가 비어있으면 여기서 '멈춤(Block)' 상태로 대기.
        # 데이터가 들어오면 즉시 깨어나서 실행.
        priority, item = pq.get()
        
        print(f"[소비] {item} 처리 시작 (우선순위: {priority})")
        time.sleep(1) # 작업 처리 흉내
        
        # 큐에게 작업이 끝났음을 알림
        pq.task_done() 


# target=consumer: 이 스레드가 실행할 함수는 'consumer'다.
# daemon=True : 메인 스레드 종료후에도 서브 스레드가 독립적으로 실행되게 함
# 여기선 join() 메서드로 특정 서브 스레드가 끝날 때 까지 메인 스레드를 대기시킴
t = threading.Thread(target=consumer, daemon=True)

# 스레드 시작 : consumer()가 무한 루프를 돌며 get()을 기다림
t.start()

# 메인 스레드인 생산자 실행
producer()

# 큐의 모든 항목이 처리될 때까지(task_done이 호출될 때까지) 대기
print("모든 작업이 끝날 때까지 대기 중...")
pq.join()
print("모든 작업 완료!")
```


### 스레드 동기화 기법

스레드가 여러 개일 때, 어떤 스레드가 먼저 실행되고 언제 끝날지는 전적으로 **운영체제(OS)의 스케줄러**가 결정한다.

스케줄러는 효율성을 위해 수시로 실행 대상을 바꾸기 때문에(Context Switching), 개발자가 개입하지 않으면 실행 순서를 예측할 수 없다. 이를 **비결정적(Non-deterministic) 특성**이라고 한다.

따라서 운영체제에게 "얘 먼저 실행해줘"라고 직접 명령할 수는 없지만, 코드 레벨에서 **스레드끼리 서로 신호를 주고받게(Coordination)** 함으로써 순서를 강제할 수는 있다

이를 동기화(Synchronization)라 함

**1) 자원 보호 (Resource Safety)**

- **설명:** 여러 스레드가 동시에 `Queue`나 변수에 접근할 때 충돌을 막는 것.
    
- **특징:** `PriorityQueue`는 내부적으로 Lock(Mutex)을 사용하여 이를 자동으로 처리해준다.
    

**2) 흐름 제어 (Flow Control)**

- **설명:** 스레드 간의 작업 순서를 맞추거나, 특정 상태를 기다리게 하는 것.
    
- **방법 A: `join()`** - "작업이 끝날 때까지 대기" (종료 보장)
    
- **방법 B: `Event`** - "신호가 올 때까지 대기" (상태 기반 협업)

#### **방법 A: `join()` 

"앞사람이 퇴근할 때까지 뒷사람은 대기해라."

가장 단순한 방법. A가 끝날 때까지 메인이 기다리고, 그 뒤에 B를 실행하는 식. 

#### **방법 B: `threading.Event` (깃발 들기)**

"내가 깃발(Event)을 들면 그때 너 출발."

 **이벤트(Event)** 객체를 하나 만들어서 신호등처럼 쓴다.

### 각각 어떻게 써먹을 수 있을까?

1. `join()` 활용: 일일 정산 리포트 생성 (Scatter-Gather 패턴)

**상황:** 매일 밤 12시에 "일일 매출", "신규 가입자", "서버 에러 로그"를 각각 집계해서 관리자에게 **하나의 이메일**로 보내야 함.

- 각 집계 작업은 시간이 걸린다 (DB 조회 등).
    
- 순서대로 하면 10초가 걸리지만, 동시에 하면 5초면 끝남(제일 작업시간 긴게 5초).
    
-  **3가지가 모두 끝난 뒤에** 이메일을 보내야 한다. (하나라도 빠지면 안 됨)

```python
import threading
import time

# 각 작업을 담당할 함수들 (실제로는 DB 쿼리 들어감)
def calculate_sales():
    print("[매출 팀] 어제 매출 집계 시작...")
    time.sleep(3) # DB 조회 시뮬레이션
    print("[매출 팀] 집계 완료!")

def count_new_users():
    print("[유저 팀] 신규 가입자 수 세는 중...")
    time.sleep(5) # 좀 더 오래 걸림
    print("[유저 팀] 카운팅 완료!")

def analyze_logs():
    print("[로그 팀] 에러 로그 분석 중...")
    time.sleep(2)
    print("[로그 팀] 분석 완료!")

# --- 메인 로직 ---
def daily_report_job():
    print("=== 📅 일일 리포트 생성 작업 시작 ===")
    
    # 1. 일꾼(스레드) 준비
    workers = [
        threading.Thread(target=calculate_sales),
        threading.Thread(target=count_new_users),
        threading.Thread(target=analyze_logs)
    ]
    
    # 2. 동시 투입 (Scatter)
    for worker in workers:
        worker.start()
    
    print("=== ⏳ 메인 스레드: 직원들 일하는 동안 다른 준비 중... ===")
    
    # 3. 퇴근 통제 (Gather) - 여기가 join의 핵심
    # 모든 직원이 일을 끝낼 때까지 메인 스레드는 여기서 기다림
    for worker in workers:
        worker.join()
        
    # 4. 마무리 (모두 join 된 이후에만 실행됨)
    print("\n✅ 모든 데이터 집계가 끝났습니다.")
    print("📧 [이메일 발송] 관리자에게 통합 리포트를 전송했습니다.")

daily_report_job()
```

```plain text
실행결과

=== 📅 일일 리포트 생성 작업 시작 ===
[매출 팀] 어제 매출 집계 시작...
[유저 팀] 신규 가입자 수 세는 중...
[로그 팀] 에러 로그 분석 중...
=== ⏳ 메인 스레드: 직원들 일하는 동안 다른 준비 중... ===
[로그 팀] 분석 완료!
[매출 팀] 집계 완료!
[유저 팀] 카운팅 완료!

✅ 모든 데이터 집계가 끝났습니다.
📧 [이메일 발송] 관리자에게 통합 리포트를 전송했습니다.
```

- **Scatter (뿌리기):** 메인 스레드가 여러 일꾼 스레드에게 "너는 A해, 너는 B해" 하고 일을 뿌려주는 단계 (`for ... start()`)
    
- **Gather (모으기):** 일꾼들이 결과를 가져올 때까지 기다렸다가 하나로 합치는 단계 (`for ... join()`)


2. `Event` 활용: 서버 초기화 대기 (Dependency Check)

**상황:** API 서버를 킴. 하지만 **DB 연결**과 **AI 모델 로딩**이 끝나기 전에는 사용자의 요청을 받으면 안되는 상황.

- **DB 연결 스레드:** 백그라운드에서 DB 접속을 시도.
    
- **메인 서버 스레드:** DB 연결이 성공했다는 신호(Event)가 올 때까지 서버 포트를 열지 않고 대기.

```python
import threading
import time

# 신호등 생성 (초기 상태: Red Light)
db_ready_event = threading.Event()

def connect_database():
    print(" [DB 스레드] 데이터베이스 연결 시도 중...")
    time.sleep(4) # 연결 과정 시뮬레이션
    print(" [DB 스레드] 연결 성공! 커넥션 풀 생성 완료.")
    
    # [깃발 들기] "준비 됐어!"라고 신호를 보냄
    db_ready_event.set() 

def start_api_server():
    print(" [서버 스레드] 서버 구동 준비...")
    
    # [대기] DB가 준비될 때까지 여기서 멈춤
    # (join은 '죽을 때'까지 기다리지만, 이건 '깃발 들 때'까지만 기다림)
    print(" [서버 스레드] DB 연결 대기 중... (Blocking)")
    db_ready_event.wait()
    
    print("\n[서버 스레드] 신호 수신! 8080 포트로 서버를 시작합니다.")
    print("    클라이언트 요청 수락 가능 상태")

# --- 실행 ---
t1 = threading.Thread(target=connect_database)
t2 = threading.Thread(target=start_api_server)

t1.start()
t2.start()

# 예시라서 메인 스레드 대기용 join 추가 (실제 서버는 계속 켜져 있음)
t1.join()
t2.join()
```

```plaintext
실행결과
[DB 스레드] 데이터베이스 연결 시도 중...
 [서버 스레드] 서버 구동 준비...
 [서버 스레드] DB 연결 대기 중... (Blocking)
 [DB 스레드] 연결 성공! 커넥션 풀 생성 완료.

[서버 스레드] 신호 수신! 8080 포트로 서버를 시작합니다.
    클라이언트 요청 수락 가능 상태
```


## 3) asyncio.PriorityQueue

`asyncio` 모듈에 포함된 클래스로, **비동기 프로그래밍(`async`/`await`) 환경**을 위해 설계된 우선순위 큐이다.

기본적인 자료구조의 원리(Min Heap)는 앞선 두 라이브러리와 같지만, "기다리는 방식"에서  차이가 있다.

### **queue.PriorityQueue와의 핵심 차이: Non-blocking**

가장 큰 특징은 데이터가 없을 때 대기하는 방식이 **Non-blocking**이라는 점이다.

- **`queue.PriorityQueue` (Blocking):**
    
    - 큐가 비어있을 때 `get()`을 하면, 데이터가 들어올 때까지 **스레드 자체가 멈춘다.**
        
    - 싱글 스레드 기반인 `asyncio` 환경에서 이걸 쓰면, 서버 멈추는 문제 발생 
        
- **`asyncio.PriorityQueue` (Non-blocking):**
    
    - 큐가 비어있을 때 `await get()`을 하면, "데이터 올 때까지 다른 작업 먼저 하고 있을게"라며 제어권(Control)을 이벤트 루프에 양보한다.
        
    - 즉, 큐를 기다리는 동안에도 서버는 다른 요청을 처리할 수 있다.

### **주의사항: 스레드 안전성 (Thread Safety)**

 이 큐는 **Not Thread-Safe**하다.
    
`asyncio`는 기본적으로 싱글 스레드(이벤트 루프)에서 돌아가기 때문에, 굳이 무거운 Lock(Mutex)을 사용하지 않도록 설계되어 있다.
    
따라서 멀티 스레드 환경(`threading` 모듈)에서는 사용하면 안 되며, 오직 `async` 함수(코루틴) 간의 통신에만 사용해야 한다.

### 코드 예시 (비동기 환경)

앞서 `threading` 예제를 `asyncio` 버전으로 변환한 형태

```python
import asyncio
import random

async def producer(queue):
    """데이터를 만들어 큐에 넣는 역할 (비동기)"""
    for i in range(5):
        priority = random.randint(1, 10)
        item = f"비동기 작업-{i}"
        
        print(f"[생산] {item} (우선순위: {priority}) 넣음")
        
        # await를 통해 넣는 동안에도 다른 작업이 틈입할 수 있음
        await queue.put((priority, item))
        await asyncio.sleep(0.5) # 비동기 대기 (Non-blocking)

async def consumer(queue):
    """큐에서 데이터를 꺼내 처리하는 역할 (비동기)"""
    while True:
        # 큐가 비어있으면 제어권을 양보하고 대기
        priority, item = await queue.get()
        
        print(f"    ▶ [소비] {item} 처리 시작 (우선순위: {priority})")
        await asyncio.sleep(1) # 작업 처리 흉내
        
        # 작업 완료 알림
        queue.task_done()

async def main():
    # 비동기 우선순위 큐 생성
    pq = asyncio.PriorityQueue()

    # 생산자와 소비자 태스크 생성 (예약)
    producer_task = asyncio.create_task(producer(pq))
    consumer_task = asyncio.create_task(consumer(pq))

    # 생산자가 모든 데이터를 넣을 때까지 대기
    await producer_task

    # 큐의 모든 항목이 소비될 때까지 대기
    print("모든 비동기 작업이 끝날 때까지 대기 중...")
    await pq.join()
    
    # 소비자는 무한 루프이므로 강제 종료 (cancel)
    consumer_task.cancel()
    print("모든 작업 완료!")

# 이벤트 루프 실행
asyncio.run(main())

```


```plaintext
[생산] 비동기 작업-0 (우선순위: 7) 넣음
    ▶ [소비] 비동기 작업-0 처리 시작 (우선순위: 7)
[생산] 비동기 작업-1 (우선순위: 10) 넣음
[생산] 비동기 작업-2 (우선순위: 9) 넣음
[생산] 비동기 작업-3 (우선순위: 7) 넣음
    ▶ [소비] 비동기 작업-3 처리 시작 (우선순위: 7)
[생산] 비동기 작업-4 (우선순위: 5) 넣음
모든 비동기 작업이 끝날 때까지 대기 중...
    ▶ [소비] 비동기 작업-4 처리 시작 (우선순위: 5)
    ▶ [소비] 비동기 작업-2 처리 시작 (우선순위: 9)
    ▶ [소비] 비동기 작업-1 처리 시작 (우선순위: 10)
모든 작업 완료!
```


## 4) sortedcontainers

sortedcontainers는 우선순위 큐 전용은 아니지만, 정렬된 상태를 유지하므로 최솟값/최댓값을 우선순위로 꺼내는 용도로는 PQ처럼 사용할 수 있다

특히 단순히 "최솟값/최댓값만 뽑는 것"을 넘어서, **데이터의 중간 조회, 수정, 삭제**가 필요한 경우 적합함


**주요 클래스 (Components)**
1. **`SortedList` (핵심):** 값이 항상 정렬된 상태로 유지되는 리스트. (우선순위 큐 구현 시 주로 사용) 

2. **`SortedDict`:** 키(Key)의 순서가 항상 정렬된 딕셔너리. 

3. `SortedSet`: 중복이 없고 정렬된 집합.



```python
from sortedcontainers import SortedList

# 우선순위 큐 생성
pq = SortedList()

# 데이터 삽입 (자동 정렬됨)
pq.add((3, "Task C"))
pq.add((1, "Task A"))
pq.add((2, "Task B"))

print(f"현재 큐: {pq}") 
# 출력: SortedList([(1, 'Task A'), (2, 'Task B'), (3, 'Task C')])

# 1. 최솟값 가져오기 (Pop Min) - heapq.heappop과 동일
min_task = pq.pop(0) 
print(f"처리된 작업: {min_task}")

# 2. 특정 값 삭제 (heapq에서는 어려운 기능)
# (2, 'Task B') 작업을 취소하고 싶음
pq.remove((2, "Task B")) 
print(f"중간 삭제 후 큐: {pq}")

# 3. 임의 접근
pq.add((5, "Task E"))
pq.add((4, "Task D"))
# 현재 2번째로 작은 값 확인
print(f"2번째 우선순위: {pq[1]}")
```
# Pq는 어떤 상황에 쓸수 있을까?

## 1. 작업 스케줄러 (Task Scheduler)

백엔드가 서버로부터 요청을 받는데, 모든 요청이 평등하지 않음

- **일반 유저:** "내 프로필 사진 보여줘" (중요도 낮음)
    
- **VIP 유저:** "지금 당장 결제해줘" (중요도 높음)
    
- **시스템 알람:** "서버 다운 직전! 경고!" (긴급, 0순위)

만약 일반 큐(FIFO)를 쓰면, 앞에 쌓인 사진 요청 100개를 처리하느라 시스템 경고를 무시해서 서버가 죽을 수도 있음로 이때 우선순위 큐를 사용.

```python

import heapq

import time

class TaskScheduler:

    def __init__(self):

        self.queue = []
        self.index = 0  # 들어온 순서를 체크하기 위한 카운터

    def add_task(self, task_name, priority):

        # 힙에 저장할 구조: (우선순위, 들어온 순서, 작업 이름)

        # 우선순위 숫자가 작을수록 먼저 실행 (Min Heap 특성 활용)

        heapq.heappush(self.queue, (priority, self.index, task_name))

        self.index += 1

        print(f"[예약] '{task_name}' (우선순위: {priority})")

    def run_next(self):

        if not self.queue:

            return None

        # 가장 우선순위 높은 작업 꺼내기

        priority, _, task_name = heapq.heappop(self.queue)

        print(f"▶ [실행] '{task_name}' 처리 중... (우선순위: {priority})")

  

# --- 사용 예시 ---

scheduler = TaskScheduler()

  
# 1. 요청들이 무작위로 들어옴

scheduler.add_task("일반 유저 이미지 로딩", priority=3)

scheduler.add_task("VIP 유저 결제 요청", priority=1)  # 중요!

scheduler.add_task("시스템 로그 저장", priority=2)

scheduler.add_task("서버 과부하 긴급 패치", priority=0) # 긴급!

  
print("-" * 30)

# 2. 작업 실행 (들어온 순서와 상관없이 중요도 순으로 실행됨)

while scheduler.queue:

    scheduler.run_next()

    time.sleep(0.5)
    
```

실행결과

```plain text
[예약] '일반 유저 이미지 로딩' (우선순위: 3)
[예약] 'VIP 유저 결제 요청' (우선순위: 1)
[예약] '시스템 로그 저장' (우선순위: 2)
[예약] '서버 과부하 긴급 패치' (우선순위: 0)
------------------------------
▶ [실행] '서버 과부하 긴급 패치' 처리 중... (우선순위: 0)
▶ [실행] 'VIP 유저 결제 요청' 처리 중... (우선순위: 1)
▶ [실행] '시스템 로그 저장' 처리 중... (우선순위: 2)
▶ [실행] '일반 유저 이미지 로딩' 처리 중... (우선순위: 3)
```

## 2. 실시간 데이터 스트림의 Top-K 모니터링

지금 가장 응답이 느린 상위 3개 요청이 뭐지?"를 알고 싶은 경우. 매번 전체 데이터를 정렬(`sort`)하면 효율이 좋지 못하다. 힙을 사용하면 전체 데이터를 다 저장하지 않고도 상위 K개만 유지할 수 있음

100만개의 요청이 있을때 sort(NlogN)는 2000만번, heap(logN)은 20번

```python

import heapq
import random

def monitor_slow_requests(log_stream, k=3):
    # 상위 k개의 느린 요청만 담을 힙 (최소 힙)
    top_k_heap = []

    print(f"--- 실시간 로그 모니터링 시작 (Top {k} 느린 요청 추적) ---")

    for request_url, response_time in log_stream:
        # 1. 힙이 아직 꽉 차지 않았다면 그냥 넣음
        if len(top_k_heap) < k:
            heapq.heappush(top_k_heap, (response_time, request_url))
        else:
            # 2. 힙이 꽉 찼다면?
            # 현재 힙의 최소값(Top 3 중 3등)보다 지금 들어온 요청이 더 느리다면 교체 => 더 느린 응답으로 교체 
            if response_time > top_k_heap[0][0]:
                heapq.heappushpop(top_k_heap, (response_time, request_url))
                

    # 결과 출력 
    print(f"\n[최종 결과] 가장 느렸던 요청 Top {k}:")
    # 힙에서 꺼내면 작은 순서대로 나오므로 내림차순 정렬해서 보여줌
    result = sorted(top_k_heap, key=lambda x: x[0], reverse=True)
    for time, url in result:
        print(f"{time}ms - {url}")

# --- 더미 데이터 스트림 생성 ---
logs = [
    ("/home", 120), ("/about", 50), ("/api/pay", 3000), 
    ("/login", 200), ("/image/1.png", 80), ("/api/search", 4500),
    ("/favicon.ico", 10), ("/admin", 2100)
]

monitor_slow_requests(logs, k=3)
```

결과

```plaintext
[최종 결과] 가장 느렸던 요청 Top 3:
4500ms - /api/search
3000ms - /api/pay
2100ms - /admin
```

## 3. 다익스트라 알고리즘

최단경로를 위한 다익스트라 알고리즘에서도 사용됨

**1) 정의**: 한 곳에서 다른 모든 곳으로 가는 최단 거리

**2) 특징:**

- **음의 간선(비용)이 없어야 함:** 거리가 -5km인 도로는 현실에 없음 이런 비현실적인 상황이 없을 때만 작동한다.
    
- **그리디(Greedy) 알고리즘:** 매 순간 "지금 가장 가까운 곳"을 선택해서 이동하면, 결과적으로 전체 최단 거리가 구해진다는 논리.

**3) 로직**: 

- **초기화:** 출발지는 0, 나머지 출발점을 제외한 모든 노드는 무한대(`INF`)로 설정.
	
- **선택 (우선순위 큐 활용):** 방문하지 않은 노드 중 **가장 최단 거리가 짧은 노드**를 선택. (여기서 **최소 힙**을 사용! O(logN))
    
- **갱신 (Relaxation):** 선택한 노드를 거쳐서 다른 이웃 노드로 가는 게, 기존에 알고 있던 길보다 더 빠른지 확인. 더 빠르면 값을 갱신하고 큐에 넣는다.

무한대(`INF`) : 엄밀히 따지면 무한대가 아닌 아주 큰 수이다, 서울에서 부산가는 최단거리를 발견했을때 400km 라면 10억km와 비교해 작으니 최단거리를 400km로 수정

```python

import heapq

INF = int(1e9)  # 무한대 값


# n: 노드 개수, m: 간선 개수
n, m = map(int, input().split())

# 시작 노드 번호
start = int(input())


# 각 노드에 연결된 노드 정보를 담는 리스트 만들기
graph = [[] for i in range(n + 1)]

# 최단 거리 테이블을 모두 무한으로 초기화
distance = [INF] * (n + 1)

  

# 모든 간선 정보 입력받기
for _ in range(m):

    a, b, c = map(int, input().split())
    graph[a].append((b, c))

  

def dijkstra(start):

    q = []

    # 시작 노드로 가기 위한 최단 경로는 0으로 설정하여, 큐에 삽입

    heapq.heappush(q, (0, start))
    distance[start] = 0


    while q:
        # 가장 최단 거리가 짧은 노드에 대한 정보 꺼내기
        dist, now = heapq.heappop(q)

        # 현재 꺼낸 거리(dist)가 이미 기록된 거리(distance[now])보다 크다면 스킵

        if distance[now] < dist:
            continue

  

        # 현재 노드와 연결된 다른 인접한 노드들을 확인

        for i in graph[now]:

            cost = dist + i[1]

            # 현재 노드를 거쳐서, 다른 노드로 이동하는 거리가 더 짧은 경우

            if cost < distance[i[0]]:

                distance[i[0]] = cost

                heapq.heappush(q, (cost, i[0]))

  

# 알고리즘 수행

dijkstra(start)

  

# 모든 노드로 가기 위한 최단 거리를 출력

for i in range(1, n + 1):

    if distance[i] == INF:
        print("INFINITY")

    else:
        print(distance[i])
        
```

노드 4개, 간선 5개일때 예시 시각화:
https://gemini.google.com/share/5c09db2e1ee7

# 힙(Heap)과 이진트리(Binary Tree)

우선순위 큐의 구현에는 힙이 사용 그리고 힙은 이진트리 구조이다.
때문에 두 개념또한 참고할 필요가 있다.

[[힙(heap)과 이진트리]]


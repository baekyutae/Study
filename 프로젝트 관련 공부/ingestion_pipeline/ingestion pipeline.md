	
## chapter 1. 기초 개념 

1. 동기(Synchronous) vs 비동기(Asynchronous) 처리

2. Producer-Consumer 패턴

	- **개념:** 생산자(API 서버)는 주문서(Task)만 넣고 빠지고, 소비자(Worker)는 주문서를 하나씩 꺼내 처리하는 구조.
    
    - **결합도(Decoupling):** API 서버가 죽어도 워커는 일할 수 있고, 워커가 죽어도 API 서버는 주문을 받을 수 있는 이유.


## chapter 2. 도구 선정 및 구성 요소 

### 3. Message Broker (우체통)

#### 개념 
메시지 브로커는 **애플리케이션(서비스) 간의 메시지를 중계하고 임시로 보관하는 미들웨어

#### 사용하는 이유

API 서버(FastAPI)가 워커(Worker)에게 함수 호출(`process_video()`)로 직접 일을 시키면(HTTP 요청 등) 다음과 같은 치명적인 문제가 발생

1. 결합도 감소 (Decoupling):

문제: 워커 서버가 죽어있으면 API 서버도 에러를 뱉고 사용자는 업로드를 못 함. (강한 결합)

해결: 브로커가 있으면 워커가 죽어도 API는 브로커에 메시지만 넣으면 끝이다. 워커는 나중에 살아나서 처리. (느슨한 결합)

2. 부하 분산 및 버퍼링 (Throttling & Buffering):

문제: 갑자기 1초에 영상 100개가 업로드되면 워커 서버가 100개를 동시에 처리하다가 메모리 부족(OOM)으로 터짐.

해결: 브로커가 100개의 메시지를 큐에 쌓아두고(Buffer), 워커는 자신의 능력껏 하나씩 가져가 시스템이 죽지 않음

3. 응답 속도 향상 (Asynchronous Processing):

문제: 영상 처리에 10분이 걸리는데, 사용자가 10분 동안 로딩 화면을 보고 있어야 한다.

해결: API는 "접수됐습니다"라고 0.1초 만에 응답하고, 실제 처리는 뒤단에서 천천히 이루어짐

#### 작동 방식

메시지 브로커의 내부 동작은 **FIFO (First-In, First-Out)** 구조를 기본으로 하며, 신뢰성을 위한 장치들이 있다.

- **Publish (발행):**
    
    - Producer(API 서버)가 메시지(`{"video_id": 123}`)를 브로커의 특정 **Exchange(교환소)나 Queue(대기열)로 보낸다.
        
- **Enqueue (적재):**
    
    - 브로커는 메시지를 메모리나 디스크에 저장. (RabbitMQ 같은 경우 디스크에 써서 영속성을 보장하기도 함)
        
- **Consume (소비):**
    
    - Consumer(Worker)는 브로커를 계속 감시(Polling)하거나 연결을 유지하다가, 메시지가 오면 가져가 작업을 시작한다.
        
- **Acknowledgement (ACK, 수신 확인):** **[핵심]**
    
    - 워커가 메시지를 가져가서 처리를 **완료**하면 브로커에게 "다 했어(ACK)"라고 신호를 보낸다.
        
    - 브로커는 ACK를 받아야만 큐에서 해당 메시지를 **삭제**.
        
    - 만약 워커가 처리 중 죽어서 ACK를 못 보내면? 브로커는 일정 시간 후 이 메시지를 다른 워커에게 다시 준다. (**무중단 처리 보장**)


#### 구현 스택들 비교

1. Redis (Remote Dictionary Server)

원래는 인메모리 데이터 저장소지만, 리스트(`List`)나 `Pub/Sub`, `Stream` 자료구조를 활용해 메시지 브로커로 널리 사용된다.

( stream vs pubsub : https://oneuptime.com/blog/post/2026-01-21-redis-streams-vs-pubsub/view) 


- **장점:**
    
    - **초고속 처리:** 모든 데이터를 RAM에서 처리하므로 지연 시간(Latency)이 극도로 낮다.
        
    - **단순성:** 설정이 매우 간편하며, 이미 캐시 시스템으로 Redis를 쓰고 있다면 추가 인프라 비용이 들지 않는다.
        
    - **다양한 자료구조:** 큐뿐만 아니라 리스트, 셋 등을 활용한 복잡한 작업 관리가 가능하다.
        
- **단점:**
    
    - **데이터 휘발성:** 전원이 꺼지면 메모리 내 메시지가 유실될 위험이 있다. (AOF/RDB 설정으로 보완 가능하나 완벽하지 않음)
        
    - **메시지 크기 제한:** 메모리 자원을 직접 사용하므로, 아주 큰 메시지나 방대한 양의 대기열을 쌓아두기에는 비용 부담이 크다.
        
- **추천 상황:** 빠른 응답 속도가 생명인 서비스, 작업 유실이 치명적이지 않은 가벼운 비동기 작업.
    

2. RabbitMQ (Advanced Message Queuing Protocol)

메시지 브로킹만을 위해 설계된 전문 소프트웨어로, 전통적인 태스크 큐 시스템의 강자다.

- **장점:**
    
    - **신뢰성 및 안정성:** 메시지 전달 보장(Delivery Guarantees) 기능이 매우 강력하며, 메시지를 디스크에 영구 저장할 수 있다.
        
    - **정교한 라우팅:** `Exchange`와 `Binding` 개념을 통해 메시지를 조건에 따라 여러 큐로 복사하거나 분류하는 작업이 매우 유연하다.
        
    - **관리 도구:** 기본적으로 제공되는 웹 UI(Management Plugin)를 통해 큐 상태를 모니터링하기 매우 좋다.
        
- **단점:**
    
    - **상대적으로 복잡한 설정:** Exchange, Queue, Routing Key 등 학습해야 할 개념이 많다.
        
    - **성능 한계:** 초당 수십만 건 이상의 초고속 스트리밍 처리에는 Redis나 Kafka보다 불리할 수 있다.
        
- **추천 상황:** 금융 결제, 주문 처리 등 **데이터 유실이 절대 있어서는 안 되는 견고한 시스템.**
    

3. Apache Kafka (Distributed Streaming Platform)

단순한 큐를 넘어, 대규모 데이터를 실시간으로 수집하고 처리하는 '이벤트 스트리밍 플랫폼'이다.

- **장점:**
    
    - **엄청난 처리량(Throughput):** 분산 아키텍처를 통해 초당 수백만 건의 데이터를 처리할 수 있다.
        
    - **데이터 영속성 및 재생(Replay):** 소비된 메시지가 즉시 삭제되지 않고 설정된 기간 동안 저장된다. 장애 발생 시 과거 시점부터 다시 데이터를 읽어올 수 있다.
        
    - **확장성:** 클러스터 구성을 통해 무한에 가까운 수평 확장(Scale-out)이 가능하다.
        
- **단점:**
    
    - **높은 운영 난이도:** 설치, 설정, 모니터링이 매우 까다로우며 별도의 관리 도구(Zookeeper 등)가 필요할 수 있다.
        
    - **단건 처리 오버헤드:** 단순히 "작업 하나 던지고 하나 받기"에는 너무 무겁고 복잡한 도구다.
        
- **추천 상황:** 대규모 로그 수집, 실시간 데이터 분석 파이프라인, 마이크로서비스(MSA) 간의 이벤트 소싱.
    

---

### 📊 기술 스택 비교 요약

|**비교 항목**|**Redis**|**RabbitMQ**|**Apache Kafka**|
|---|---|---|---|
|**주요 용도**|단순 작업 큐, 실시간 알림|복잡한 라우팅, 신뢰성 작업|대규모 스트리밍, 로그 수집|
|**저장 위치**|메모리 (In-memory)|메모리 + 디스크 (Mixed)|디스크 (Persistent Log)|
|**속도**|**최상**|중상|상 (일괄 처리 최적화)|
|**신뢰성**|낮음 (유실 가능성)|**높음 (ACK 기능 강력)**|**매우 높음 (데이터 복제)**|
|**설계 철학**|가볍고 빠른 처리|안정적인 메시지 전달|고성능 데이터 스트리밍|



### 4. Task Queue 

#### 메시지 브로커와의 관계성 (Relationship)

"포함 관계"이자 "구현체와 자료구조의 관계"다.

- **메시지 브로커 (Software/Infrastructure):** Redis, RabbitMQ, Kafka 같은 **소프트웨어 그 자체**를 말한다. 우체국 건물이나 서버 프로그램이다.
    
- **태스크 큐 (Logical Data Structure):** 브로커 내부에서 관리되는 작업 리스트(List/Queue)**다. 우체국 내부의 '사서함 101호', '사서함 102호'다.
    
- **1:N 관계:** 하나의 메시지 브로커(RabbitMQ 서버 1대) 안에 여러 개의 태스크 큐(영상처리 큐, 이메일발송 큐, 로그저장 큐)를 만들 수 있다.
    
- **역할 분담:** 브로커는 큐를 관리하고, 라우팅(어떤 메시지를 어떤 큐에 넣을지)을 담당하는 시스템이다.


#### 작동 방식 (Mechanism)

기본적으로 **FIFO (First-In, First-Out)** 구조를 따르며, 생산자와 소비자 패턴으로 돌아간다.

- **Enqueue (생산):** API 서버가 `{"video_id": 123, "action": "extract_audio"}` 같은 메시지를 만들어 브로커에게 던진다.
    
- **Queueing (대기):** 브로커는 이 메시지를 내부의 특정 리스트(Queue)에 저장한다. 이때 디스크에 써서 영구 보존(Persistence)할지, 메모리에 둘지 결정한다.
    
- **Dequeue/Prefetch (소비):** 대기 중인 워커(Worker)가 큐에서 메시지를 가져간다. 보통 워커는 멍하니 있지 않고 주기적으로 큐를 확인(Polling)하거나, 브로커가 워커에게 밀어준다(Push).
    
- **Processing & ACK (처리 및 확인):**
    
    - 워커가 작업을 수행한다.
        
    - 성공하면 **ACK(Acknowledgement)**를 브로커에 보낸다. 브로커는 그때서야 큐에서 메시지를 지운다.
        
    - 실패하거나 ACK가 안 오면? 브로커는 일정 시간 뒤 이 메시지를 다시 큐에 넣거나(Requeue), 실패 전용 큐(DLQ)로 보낸다.


## chapter 3. 워커(Worker)

워커는 메시지 브로커로부터 할 일을 전달받아 **실제 비즈니스 로직을 실행하는 프로세스**다

#### 주요 작업

- **무거운 작업 전담:** CPU나 메모리를 많이 사용하는 작업(영상 분석, 인코딩, AI 추론)을 API 서버에서 분리하여 처리한다.
    
- **시스템 확장성 제공:** 처리해야 할 영상이 많아지면 워커 프로세스의 개수만 늘림으로써(Horizontal Scaling) 대응이 가능하다.
    
- **장시간 작업 수행:** HTTP 요청 제한 시간(보통 수십 초)에 얽매이지 않고, 몇 분에서 몇 시간 걸리는 작업을 안정적으로 수행한다.


### 작동 방식 (Mechanism)

- **리스닝(Listening):** 큐를 지속적으로 감시하며 새로운 메시지가 들어오는지 확인한다.
    
- **가져오기(Fetch):** 메시지가 도착하면 이를 자신의 메모리로 가져온다. 이때 **Prefetch Count**(한 번에 몇 개를 가져올지) 설정이 중요하다.
    
- **실행(Execute):** 메시지에 담긴 데이터(예: `video_id`)를 바탕으로 실제 작업(스토리지에서 영상 다운로드 -> STT 추출 -> 벡터 DB 저장)을 수행한다.
    
- **결과 보고(Ack/Nack):**
    
    - **ACK(Success):** 작업 완료를 알리고 브로커가 큐에서 메시지를 지우도록 한다.
        
	    - **NACK/Requeue(Failure):** 실패 시 메시지를 다시 큐에 넣거나 버린다


### 고려해야할 사항

- **직렬화(Serialization/Pickling):**
    
    - 파이썬 객체(함수, 변수)를 0과 1로 바꿔서 브로커에 저장하고, 워커가 다시 복구하는 과정.
        
    - **주의:** DB 객체(ORM 모델) 자체를 큐에 넘기지 말고, `video_id` 같은 **PK(기본키)**만 넘겨야 하는 이유.
        
- **Prefetch Count : **
    
    - 워커가 멍때리지 않게 미리 몇 개의 일을 가져와야 할까?
        
    - 영상 처리는 오래 걸리니까 `prefetch=1`로 설정해야 하는 이유 (Fair Dispatch).
        
- **Concurrency (동시성):**
    
    - **Process vs Thread:** 영상 인코딩/임베딩은 CPU를 많이 쓰므로(CPU-bound), 스레드가 아닌 **프로세스** 기반 워커를 띄워야 함.

	프로세스(Process) vs 스레드(Thread)

	영상 처리 관련 작업은 cpu 점유율이 높은 작업(cpu bound) 즉 사이사이 i/o등으로 cpu가 쉰다거나 하는 시간이 거의 없음

  파이썬은 gil(global interpreter lock)이라는 mutex가 존재(cpython 한정) 때문에 하나의 스레드가 작업 하고 있을때 lock이 걸려 다른 스레드가 자원을 동시에 점유하지 못함

  이 두가지 요소가 합쳐져 영상 작업중에는 끝날떄까지 gil이 걸려 다른 스레드가 항상 놀고 있으므로 멀티 스레드 환경이 의미가 없음

  때문에 독립된 환경에서 작업하는 멀티프로세스가 더 작업에 효율적임, 단 각 작업마다 메모리를 따로 점유하므로 메모리 용량을 고려하여 프로세스 갯수를 결정해야함 (보통 코어수+1)
	
	참고 자료:	
	https://seungriyou.github.io/posts/python-global-interpreter-lock/


	단 **Python 3.13부터는 GIL을 선택적으로 끌 수 있는 프리 스레딩(Free-threading)** 모드가 도입 되었으나 라이브러리 호환 여부등이 아직 확인 안되었으므로 보류
	
### 워커 분리

#### 1. Media Worker (전처리 담당)

- **역할:** 업로드된 비디오 파일(S3/GCS)을 다운로드하여 오디오(`.mp3`)만 추출하고 다시 업로드.
    
- **분리 이유:**
    
    - **CPU 부하 격리:** FFmpeg를 돌리는 작업은 CPU를 많이 활용하는 작업. 만약 이 워커가 AI 요청까지 같이 한다면, CPU가 바빠서 AI API 응답을 제때 못 받을 수 있다.
        
    - **빠른 실패 (Fail Fast):** 파일 자체가 깨진 경우(Corrupted File) 여기서 바로 걸러내야 뒤쪽의 비싼 AI 비용을 아낄 수 있다.
        


#### 2. AI Worker (핵심 분석 담당)

- **역할:** 추출된 오디오를 Vertex AI(STT)에 보내 텍스트를 받고, 이를 청킹하여 다시 임베딩 모델에 보낸다.
    
- **분리 이유:**
    
    - **가장 긴 대기 시간:** STT는 영상 길이만큼 시간이 걸릴 수 있으며. 이 워커는 대부분 외부 API 응답을 기다리는 상태.
        
    - **독립적 확장 (Auto-scaling):** 사용자가 몰릴 때 병목이 발생하는 지점이다. 때문에 `Media Worker`는 2개만 있어도 되지만, `AI Worker`는 50개로 늘려야 할 수도 있다. 이렇게 **따로 늘리고 줄이기 위해** 분리.
        
    - **에러 처리 (Retry):** 타임아웃이나 Rate Limit 발생시. 이곳에만 집중적으로 재시도(Retry) 정책을 적용하기 유리하다.
        

#### 3. Index Worker (저장 담당)

- **역할:** 분석된 결과(스크립트, 벡터)를 DB와 Vector DB(Pinecone, Weaviate 등)에 트랜잭션으로 저장.
    
- **분리 이유:**
    
    - **데이터 정합성:** 앞의 AI 작업이 아무리 오래 걸려도, 저장은 **순식간에** 끝나야 한다.
        
    - **커넥션 관리:** DB 커넥션 풀(Connection Pool)은 한정되어 있다. AI 워커가 DB 연결을 잡고 10분 동안 기다리고 있으면 커넥션 풀 고갈이 일어 날 수 있다. 저장을 전담하는 워커만 DB에 짧고 굵게 접근하게 하여 **DB 부하를 최소화 한다.

## chapter . 모니터링 및 운영 (Observability)**

보이지 않으면 관리할 수 없습니다.

- **모니터링 도구:**
    
    - **Flower:** Celery 전용 모니터링 웹 UI.
        
- **주요 지표:**
    
    - **Queue Depth:** 큐에 얼마나 일이 쌓여 있는가? (너무 쌓이면 워커 증설 신호)
        
    - **Latency:** 작업 하나 처리하는 데 걸리는 시간.

## 작성 예정



2. 인증 권한 관리 (Authentication): `Presigned URL`이 나오지만, 워커가 비공개(Private) 버킷의 파일을 다운로드하려면 별도 권한이 필요

3. 텍스트 청킹 전략 (Chunking Strategy): 단순히 글자 수로 자르면 문맥이 끊긴다
	• **문제:** "아버지가 방에 들어" / "가신다" 처럼 잘리면 검색이 안 됩니다.

	• **해결책 (공부 필요):** **Semantic Chunking** 또는 **RecursiveCharacterTextSplitter**.

    ◦ `LangChain` 라이브러리를 활용해 문단이나 문장 단위로 의미 있게 자르는 법.

4. 각 워커가 역할을 수행하기 위해선 뭐가 필요하고 원리가 뭔지
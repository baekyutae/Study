
## Step 1. 기초 개념 (Why & What)

1. 동기(Synchronous) vs 비동기(Asynchronous) 처리

2. Producer-Consumer 패턴

	- **개념:** 생산자(API 서버)는 주문서(Task)만 넣고 빠지고, 소비자(Worker)는 주문서를 하나씩 꺼내 처리하는 구조.
    
    - **결합도(Decoupling):** API 서버가 죽어도 워커는 일할 수 있고, 워커가 죽어도 API 서버는 주문을 받을 수 있는 이유.




## Step 2. 도구 선정 및 구성 요소 (The Tools)

### 3. Message Broker (우체통)

#### 개념 
메시지 브로커는 **애플리케이션(서비스) 간의 메시지를 중계하고 임시로 보관하는 미들웨어

#### 사용하는 이유

API 서버(FastAPI)가 워커(Worker)에게 함수 호출(`process_video()`)로 직접 일을 시키면(HTTP 요청 등) 다음과 같은 치명적인 문제가 발생

1. 결합도 감소 (Decoupling):

문제: 워커 서버가 죽어있으면 API 서버도 에러를 뱉고 사용자는 업로드를 못 함. (강한 결합)

해결: 브로커가 있으면 워커가 죽어도 API는 브로커에 메시지만 넣으면 끝이다. 워커는 나중에 살아나서 처리. (느슨한 결합)

2. 부하 분산 및 버퍼링 (Throttling & Buffering):

문제: 갑자기 1초에 영상 100개가 업로드되면 워커 서버가 100개를 동시에 처리하다가 메모리 부족(OOM)으로 터짐.

해결: 브로커가 100개의 메시지를 큐에 쌓아두고(Buffer), 워커는 자신의 능력껏 하나씩 가져가 시스템이 죽지 않음

3. 응답 속도 향상 (Asynchronous Processing):

문제: 영상 처리에 10분이 걸리는데, 사용자가 10분 동안 로딩 화면을 보고 있어야 한다.

해결: API는 "접수됐습니다"라고 0.1초 만에 응답하고, 실제 처리는 뒤단에서 천천히 이루어짐

#### 작동 방식

메시지 브로커의 내부 동작은 **FIFO (First-In, First-Out)** 구조를 기본으로 하며, 신뢰성을 위한 장치들이 있다.

- **Publish (발행):**
    
    - Producer(API 서버)가 메시지(`{"video_id": 123}`)를 브로커의 특정 **Exchange(교환소)**나 **Queue(대기열)**로 보낸다.
        
- **Enqueue (적재):**
    
    - 브로커는 메시지를 메모리나 디스크에 저장. (RabbitMQ 같은 경우 디스크에 써서 영속성을 보장하기도 함)
        
- **Consume (소비):**
    
    - Consumer(Worker)는 브로커를 계속 감시(Polling)하거나 연결을 유지하다가, 메시지가 오면 가져가 작업을 시작한다.
        
- **Acknowledgement (ACK, 수신 확인):** **[핵심]**
    
    - 워커가 메시지를 가져가서 처리를 **완료**하면 브로커에게 "다 했어(ACK)"라고 신호를 보낸다.
        
    - 브로커는 ACK를 받아야만 큐에서 해당 메시지를 **삭제**.
        
    - 만약 워커가 처리 중 죽어서 ACK를 못 보내면? 브로커는 일정 시간 후 이 메시지를 다른 워커에게 다시 준다. (**무중단 처리 보장**)


#### 구현 스택들 비교

1. Redis (Remote Dictionary Server)

원래는 인메모리 데이터 저장소지만, 리스트(`List`)나 `Pub/Sub`, `Stream` 자료구조를 활용해 메시지 브로커로 널리 사용된다.

- **장점:**
    
    - **초고속 처리:** 모든 데이터를 RAM에서 처리하므로 지연 시간(Latency)이 극도로 낮다.
        
    - **단순성:** 설정이 매우 간편하며, 이미 캐시 시스템으로 Redis를 쓰고 있다면 추가 인프라 비용이 들지 않는다.
        
    - **다양한 자료구조:** 큐뿐만 아니라 리스트, 셋 등을 활용한 복잡한 작업 관리가 가능하다.
        
- **단점:**
    
    - **데이터 휘발성:** 전원이 꺼지면 메모리 내 메시지가 유실될 위험이 있다. (AOF/RDB 설정으로 보완 가능하나 완벽하지 않음)
        
    - **메시지 크기 제한:** 메모리 자원을 직접 사용하므로, 아주 큰 메시지나 방대한 양의 대기열을 쌓아두기에는 비용 부담이 크다.
        
- **추천 상황:** 빠른 응답 속도가 생명인 서비스, 작업 유실이 치명적이지 않은 가벼운 비동기 작업.
    

2. RabbitMQ (Advanced Message Queuing Protocol)

메시지 브로킹만을 위해 설계된 전문 소프트웨어로, 전통적인 태스크 큐 시스템의 강자다.

- **장점:**
    
    - **신뢰성 및 안정성:** 메시지 전달 보장(Delivery Guarantees) 기능이 매우 강력하며, 메시지를 디스크에 영구 저장할 수 있다.
        
    - **정교한 라우팅:** `Exchange`와 `Binding` 개념을 통해 메시지를 조건에 따라 여러 큐로 복사하거나 분류하는 작업이 매우 유연하다.
        
    - **관리 도구:** 기본적으로 제공되는 웹 UI(Management Plugin)를 통해 큐 상태를 모니터링하기 매우 좋다.
        
- **단점:**
    
    - **상대적으로 복잡한 설정:** Exchange, Queue, Routing Key 등 학습해야 할 개념이 많다.
        
    - **성능 한계:** 초당 수십만 건 이상의 초고속 스트리밍 처리에는 Redis나 Kafka보다 불리할 수 있다.
        
- **추천 상황:** 금융 결제, 주문 처리 등 **데이터 유실이 절대 있어서는 안 되는 견고한 시스템.**
    

3. Apache Kafka (Distributed Streaming Platform)

단순한 큐를 넘어, 대규모 데이터를 실시간으로 수집하고 처리하는 '이벤트 스트리밍 플랫폼'이다.

- **장점:**
    
    - **엄청난 처리량(Throughput):** 분산 아키텍처를 통해 초당 수백만 건의 데이터를 처리할 수 있다.
        
    - **데이터 영속성 및 재생(Replay):** 소비된 메시지가 즉시 삭제되지 않고 설정된 기간 동안 저장된다. 장애 발생 시 과거 시점부터 다시 데이터를 읽어올 수 있다.
        
    - **확장성:** 클러스터 구성을 통해 무한에 가까운 수평 확장(Scale-out)이 가능하다.
        
- **단점:**
    
    - **높은 운영 난이도:** 설치, 설정, 모니터링이 매우 까다로우며 별도의 관리 도구(Zookeeper 등)가 필요할 수 있다.
        
    - **단건 처리 오버헤드:** 단순히 "작업 하나 던지고 하나 받기"에는 너무 무겁고 복잡한 도구다.
        
- **추천 상황:** 대규모 로그 수집, 실시간 데이터 분석 파이프라인, 마이크로서비스(MSA) 간의 이벤트 소싱.
    

---

### 📊 기술 스택 비교 요약

|**비교 항목**|**Redis**|**RabbitMQ**|**Apache Kafka**|
|---|---|---|---|
|**주요 용도**|단순 작업 큐, 실시간 알림|복잡한 라우팅, 신뢰성 작업|대규모 스트리밍, 로그 수집|
|**저장 위치**|메모리 (In-memory)|메모리 + 디스크 (Mixed)|디스크 (Persistent Log)|
|**속도**|**최상**|중상|상 (일괄 처리 최적화)|
|**신뢰성**|낮음 (유실 가능성)|**높음 (ACK 기능 강력)**|**매우 높음 (데이터 복제)**|
|**설계 철학**|가볍고 빠른 처리|안정적인 메시지 전달|고성능 데이터 스트리밍|



### 4. Task Queue 

#### 메시지 브로커와의 관계성 (Relationship)

"포함 관계"이자 "구현체와 자료구조의 관계"다.

- **메시지 브로커 (Software/Infrastructure):** Redis, RabbitMQ, Kafka 같은 **소프트웨어 그 자체**를 말한다. 우체국 건물이나 서버 프로그램이다.
    
- **태스크 큐 (Logical Data Structure):** 브로커 내부에서 관리되는 작업 리스트(List/Queue)**다. 우체국 내부의 '사서함 101호', '사서함 102호'다.
    
- **1:N 관계:** 하나의 메시지 브로커(RabbitMQ 서버 1대) 안에 여러 개의 태스크 큐(영상처리 큐, 이메일발송 큐, 로그저장 큐)를 만들 수 있다.
    
- **역할 분담:** 브로커는 큐를 관리하고, 라우팅(어떤 메시지를 어떤 큐에 넣을지)을 담당하는 시스템이다.


#### 작동 방식 (Mechanism)

기본적으로 **FIFO (First-In, First-Out)** 구조를 따르며, 생산자와 소비자 패턴으로 돌아간다.

- **Enqueue (생산):** API 서버가 `{"video_id": 123, "action": "extract_audio"}` 같은 메시지를 만들어 브로커에게 던진다.
    
- **Queueing (대기):** 브로커는 이 메시지를 내부의 특정 리스트(Queue)에 저장한다. 이때 디스크에 써서 영구 보존(Persistence)할지, 메모리에 둘지 결정한다.
    
- **Dequeue/Prefetch (소비):** 대기 중인 워커(Worker)가 큐에서 메시지를 가져간다. 보통 워커는 멍하니 있지 않고 주기적으로 큐를 확인(Polling)하거나, 브로커가 워커에게 밀어준다(Push).
    
- **Processing & ACK (처리 및 확인):**
    
    - 워커가 작업을 수행한다.
        
    - 성공하면 **ACK(Acknowledgement)**를 브로커에 보낸다. 브로커는 그때서야 큐에서 메시지를 지운다.
        
    - 실패하거나 ACK가 안 오면? 브로커는 일정 시간 뒤 이 메시지를 다시 큐에 넣거나(Requeue), 실패 전용 큐(DLQ)로 보낸다.


## Step 3. 워커(Worker)의 동작 원리 (How it works)

워커는 메시지 브로커로부터 할 일을 전달받아 **실제 비즈니스 로직을 실행하는 프로세스**다

#### 주요 작업

- **무거운 작업 전담:** CPU나 메모리를 많이 사용하는 작업(영상 분석, 인코딩, AI 추론)을 API 서버에서 분리하여 처리한다.
    
- **시스템 확장성 제공:** 처리해야 할 영상이 많아지면 워커 프로세스의 개수만 늘림으로써(Horizontal Scaling) 대응이 가능하다.
    
- **장시간 작업 수행:** HTTP 요청 제한 시간(보통 수십 초)에 얽매이지 않고, 몇 분에서 몇 시간 걸리는 작업을 안정적으로 수행한다.


### 작동 방식 (Mechanism)

- **리스닝(Listening):** 큐를 지속적으로 감시하며 새로운 메시지가 들어오는지 확인한다.
    
- **가져오기(Fetch):** 메시지가 도착하면 이를 자신의 메모리로 가져온다. 이때 **Prefetch Count**(한 번에 몇 개를 가져올지) 설정이 중요하다.
    
- **실행(Execute):** 메시지에 담긴 데이터(예: `video_id`)를 바탕으로 실제 작업(S3에서 영상 다운로드 -> STT 추출 -> 벡터 DB 저장)을 수행한다.
    
- **결과 보고(Ack/Nack):**
    
    - **ACK(Success):** 작업 완료를 알리고 브로커가 큐에서 메시지를 지우도록 한다.
        
	    - **NACK/Requeue(Failure):** 실패 시 메시지를 다시 큐에 넣거나 버린다




- **직렬화(Serialization/Pickling):**
    
    - 파이썬 객체(함수, 변수)를 0과 1로 바꿔서 브로커에 저장하고, 워커가 다시 복구하는 과정.
        
    - **주의:** DB 객체(ORM 모델) 자체를 큐에 넘기지 말고, `video_id` 같은 **PK(기본키)**만 넘겨야 하는 이유.
        
- **Prefetch Count (한 번에 가져오기):**
    
    - 워커가 멍때리지 않게 미리 몇 개의 일을 가져와야 할까?
        
    - 영상 처리는 오래 걸리니까 `prefetch=1`로 설정해야 하는 이유 (Fair Dispatch).
        
- **Concurrency (동시성):**
    
    - **Process vs Thread:** 영상 인코딩/임베딩은 CPU를 많이 쓰므로(CPU-bound), 스레드가 아닌 **프로세스** 기반 워커를 띄워야 함.



### 워커 분리

#### 1. Media Worker (전처리 담당)

- **역할:** 업로드된 비디오 파일(S3/GCS)을 다운로드하여 오디오(`.mp3`)만 추출하고 다시 업로드합니다.
    
- **분리 이유:**
    
    - **CPU 부하 격리:** FFmpeg를 돌리는 작업은 CPU를 엄청나게 잡아먹습니다. 만약 이 워커가 AI 요청까지 같이 한다면, CPU가 바빠서 AI API 응답을 제때 못 받을 수 있습니다.
        
    - **빠른 실패 (Fail Fast):** 파일 자체가 깨진 경우(Corrupted File) 여기서 바로 걸러내야 뒤쪽의 비싼 AI 비용을 아낄 수 있습니다.
        

#### 2. AI Worker (핵심 분석 담당)

- **역할:** 추출된 오디오를 Vertex AI(STT)에 보내 텍스트를 받고, 이를 청킹하여 다시 임베딩 모델에 보냅니다.
    
- **분리 이유:**
    
    - **가장 긴 대기 시간:** STT는 영상 길이만큼 시간이 걸릴 수 있습니다. 이 워커는 대부분 **"외부 API 응답을 기다리는 상태"**입니다.
        
    - **독립적 확장 (Auto-scaling):** 사용자가 몰릴 때 병목이 발생하는 곳은 바로 여기입니다. `Media Worker`는 2개만 있어도 되지만, `AI Worker`는 50개로 늘려야 할 수도 있습니다. 이렇게 **따로 늘리고 줄이기 위해** 분리합니다.
        
    - **에러 처리 (Retry):** 외부 API는 타임아웃이나 Rate Limit 오류가 잦습니다. 이곳에만 집중적으로 재시도(Retry) 정책을 적용하기 유리합니다.
        

#### 3. Index Worker (저장 담당)

- **역할:** 분석된 결과(스크립트, 벡터)를 DB와 Vector DB(Pinecone, Weaviate 등)에 트랜잭션으로 안전하게 저장합니다.
    
- **분리 이유:**
    
    - **데이터 정합성:** 앞의 AI 작업이 아무리 오래 걸려도, 저장은 **순식간에** 끝나야 합니다.
        
    - **커넥션 관리:** DB 커넥션 풀(Connection Pool)은 한정되어 있습니다. AI 워커가 DB 연결을 잡고 10분 동안 멍때리고 있으면 DB가 터집니다. 저장을 전담하는 워커만 DB에 짧고 굵게 접근하게 하여 **DB 부하를 최소화**합니다.



## Step 4. 신뢰성 및 안정성 (Reliability)



### 1. Ingestion Pipeline 내부가 멈출 때 (Broker, Worker)

#### A. 메시지 브로커 (RabbitMQ/Redis) 장애 대응

- **증상:** API 서버가 메시지를 보낼 수 없거나, 큐에 있던 메시지가 날아감.
    
- **대응 전략:**
    
    1. **메시지 영속성 (Persistence):** RabbitMQ의 `Durable Queue`나 Redis의 `AOF(Append Only File)` 설정을 켜서, 브로커가 재부팅되어도 디스크에서 메시지를 복구할 수 있게 합니다.
        
    2. **클러스터링 (High Availability):** 단일 노드가 아니라 3대 이상의 클러스터로 구성하여 하나가 죽어도 나머지가 동작하게 합니다. (Redis Sentinel 등)
        

#### B. 워커 (Worker) 프로세스 장애 대응

- **증상:** 영상 처리 중 워커가 메모리 부족(OOM)으로 강제 종료됨.
    
- **대응 전략:**
    
    1. **Late ACK (후행 승인):** 워커가 메시지를 받자마자 "처리 완료(ACK)"를 보내는 게 아니라, **모든 작업이 끝난 뒤에 ACK**를 보냅니다. 워커가 중간에 죽으면 ACK가 안 오므로 브로커는 일정 시간(Visibility Timeout) 뒤에 다른 워커에게 일을 다시 줍니다.
        
    2. **멱등성 (Idempotency):** 워커가 죽어서 재실행될 때, 이미 처리된 앞부분(예: 오디오 추출)을 또 하지 않도록 DB 상태를 체크합니다. (`if task.status == 'AUDIO_EXTRACTED': continue`)


### 2. DB / Storage 영역이 멈출 때

#### A. DB (PostgreSQL) 연결 실패/지연

- **증상:** 커넥션 풀이 꽉 차거나, DB 서버 패치로 일시 다운됨.
    
- **대응 전략:**
    
    1. **서킷 브레이커 (Circuit Breaker):** DB 에러가 연속 5번 발생하면, 워커가 계속 DB를 찌르지 않고 잠시(예: 30초) 동안 요청을 차단합니다. "DB야 아프니? 30초만 쉬게 해 줄게."라는 배려입니다.
        
    2. **트랜잭션 롤백 (Atomic Transaction):** 벡터 DB에는 저장했는데 메인 DB 저장에 실패하면? **Saga 패턴**이나 보상 트랜잭션을 통해 벡터 DB의 데이터도 지워버려 데이터 불일치(Inconsistency)를 막습니다.
        

#### B. 스토리지 (S3/GCS) 네트워크 오류

- **증상:** 파일 다운로드/업로드 중 타임아웃 발생.
    
- **대응 전략:**
    
    1. **지수적 백오프 (Exponential Backoff):** 네트워크는 일시적인 오류가 많습니다. 즉시 재시도하지 않고 1초, 2초, 4초, 8초... 간격을 늘려가며 재시도합니다.


### 3. AI Model (Vertex AI / Local)이 멈출 때

가장 예측 불가능하고 비용이 많이 드는 영역입니다.

#### A. 외부 API (Vertex AI) 장애/제한

- **증상:** 구글 서버가 `500 Error`를 뱉거나, `429 Too Many Requests` (요청 제한 초과) 발생.
    
- **대응 전략:**
    
    1. **Rate Limiter (토큰 버킷):** 워커가 무작정 요청을 보내지 않고, Redis에 토큰을 넣어두고 토큰을 가져간 녀석만 API를 호출하게 하여 **분당 요청 수(RPM)**를 스스로 제어합니다.
        
    2. **Jitter (랜덤 대기):** 재시도할 때 모든 워커가 정확히 2초 뒤에 동시에 요청하면 다시 터집니다. 2초 + (0~500ms 랜덤) 시간을 섞어서 요청을 분산시킵니다.
        

#### B. 로컬 모델 (GPU) 장애

- **증상:** GPU 메모리(VRAM)가 꽉 차서 `CUDA Out Of Memory` 에러 발생.
    
- **대응 전략:**
    
    1. **프로세스 격리:** 워커가 메인 프로세스 안에서 모델을 돌리지 않고, 별도의 서브 프로세스로 실행합니다. 모델이 죽어도 워커 본체는 살아서 에러 리포팅을 할 수 있습니다.
        
    2. **Batch Size 조절:** OOM 에러가 나면 배치 사이즈를 절반으로 줄여서 자동으로 재시도하는 로직을 넣습니다.

### 위 방식들이 안될때: Dead Letter Queue (DLQ)

위의 모든 노력을 했는데도 (예: 재시도 5회 초과) 실패하는 작업의 경우

- **개념:** "가망 없는 메시지"를 버리지 않고 **'Dead Letter Queu'이라는 별도 큐로 옮긴다.
    
- **후속 조치:**
    
    1. 메인 큐를 막지 않고 다음 작업을 진행합니다.
        
    2. 개발자에게 슬랙/이메일로 "DLQ에 실패한 작업 도착" 알림을 보냅니다.
        
    3. 나중에 개발자가 원인을 분석하고(예: 파일 깨짐), 수정 후 DLQ의 메시지를 다시 메인 큐로 넣습니다(Replay).
        

### 💡 요약: 한 문장으로 기억하기

> **"워커는 ACK로 재작업을 보장하고, DB는 서킷 브레이커로 보호하며, AI는 백오프(Backoff)로 달래고, 그래도 안 되면 DLQ에 격리한다."**






- **ACK (Acknowledgement) / NACK:**
    
    - "나 일 다 했어(ACK)"라고 브로커에 알려줘야 큐에서 메시지가 삭제됨.
        
    - 일하다가 워커가 죽으면? ACK가 안 왔으니 다른 워커가 다시 가져감.
        
- **Visibility Timeout (가시성 시간 초과):**
    
    - 워커 A가 영상을 처리하는 10분 동안, 워커 B가 같은 영상을 가져가지 못하게 숨기는 시간 설정.
        
- **Retry Policy (재시도 전략):**
    
    - 네트워크 에러면 재시도 OK, 코드 에러면 재시도 X.
        
    - Exponential Backoff (1초, 2초, 4초... 뒤에 재시도).
        
- **DLQ (Dead Letter Queue):**
    
    - 5번 재시도해도 실패한 '독성 메시지(Poison Pill)'를 따로 빼두는 쓰레기통. 왜 필요한가?


### **Step 5. 모니터링 및 운영 (Observability)**

보이지 않으면 관리할 수 없습니다.

- **모니터링 도구:**
    
    - **Flower:** Celery 전용 모니터링 웹 UI.
        
- **주요 지표:**
    
    - **Queue Depth:** 큐에 얼마나 일이 쌓여 있는가? (너무 쌓이면 워커 증설 신호)
        
    - **Latency:** 작업 하나 처리하는 데 걸리는 시간.

## 작성 예정

1. 이벤트 트리거 연결 고리 (The Connection): 비디오 업로드가 완료 되었을 떄 어떻게 메세지 브로커에게 알릴건지

2. 인증 권한 관리 (Authentication): `Presigned URL`이 나오지만, 워커가 비공개(Private) 버킷의 파일을 다운로드하려면 별도 권한이 필요

3. 텍스트 청킹 전략 (Chunking Strategy): 단순히 글자 수로 자르면 문맥이 끊긴다
	• **문제:** "아버지가 방에 들어" / "가신다" 처럼 잘리면 검색이 안 됩니다.

	• **해결책 (공부 필요):** **Semantic Chunking** 또는 **RecursiveCharacterTextSplitter**.

    ◦ `LangChain` 라이브러리를 활용해 문단이나 문장 단위로 의미 있게 자르는 법.